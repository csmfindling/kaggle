First model : ann_1 : 14 2D convolutional layers with batchnorm layer after each convolution. Residual learning every two convolutional layer. No pooling layers. One dense layer as output. Categorical entropy as loss function and adam for weights learning. Under Lasagne

Second model : ann_2 : 2 2D convolutional layers with batchnorm layer and maxPool after each convolution. Two dense layer as output. Categorical entropy as loss function and adam for weights learning. Under Blocks
